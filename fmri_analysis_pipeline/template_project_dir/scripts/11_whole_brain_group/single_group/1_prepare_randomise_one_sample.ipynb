{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "import glob\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tasks and cons from your BIDS/code/contrasts.tsv file\n",
    "# Second column is either 'description' or 'desc' in constrasts.tsv\n",
    "def get_cons_and_tasks(proj_dir, second_column='description'):\n",
    "    df = pd.read_csv(proj_dir + \"data/BIDS/code/contrasts.tsv\", sep=\"\\t\")\n",
    "    cons = [[] for i in range(len(pd.unique(df['task'])))] \n",
    "\n",
    "    tasks = []\n",
    "    for i, row in df.iterrows():\n",
    "        if row['task'] not in tasks:\n",
    "            tasks.append(row['task'])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        cons[tasks.index(row['task'])].append(\"%s\" % (row[second_column].lower()))\n",
    "    return cons, tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edit this line for your project\n",
    "proj_dir = 'PATH_TO_PROJECT'\n",
    "\n",
    "cons, tasks = get_cons_and_tasks(proj_dir)\n",
    "print(type(cons))\n",
    "#cons = [cons]\n",
    "\n",
    "# CHANGE TO False IF YOU SET THE USE-ITERATIVE-LEAVE-ONE-OUT FLAG TO FALSE FOR 2ND LEVEL ANALYSES\n",
    "iterative = True #Did you do iterative subject-level modeling?\n",
    "\n",
    "tier_proj_dir = proj_dir\n",
    "tier_dir = op.join(tier_proj_dir,'TIER')\n",
    "copes_dir = op.join(tier_dir,'original_data','copes')\n",
    "varcopes_dir = op.join(tier_dir,'original_data','varcopes')\n",
    "whole_group_design_dir = op.join(tier_dir,'analysis_data','group_analysis')\n",
    "os.makedirs(whole_group_design_dir, exist_ok = True)\n",
    "\n",
    "print(cons, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_idx, task in enumerate(tasks):\n",
    "#     print(\"current task: \" + tasks[task_idx])\n",
    "#     print(task_idx)\n",
    "    \n",
    "    # subject CSV == list of subj IDs to include in this analysis \n",
    "    # THIS EXPECTS YOU TO HAVE PER-TASK CSVs NAMED ACCORDING TO PATTERN BELOW; CSV IN SPECIFIED DIR. \n",
    "    # LIST SUBJJECTS IN BIDS FORMAT -- e.g. sub-SAXEEMOfd23 (i.e., with no underscores, with 'sub-' prefix)\n",
    "    subject_lists = op.join(proj_dir, 'scripts/10_whole_brain_group/subject_lists') \n",
    "    subject_file = op.join(subject_lists, 'subjects_task-{}.csv'.format(task))\n",
    "    participant_IDs = pd.read_csv(subject_file, header=None)\n",
    "    print(participant_IDs)\n",
    "\n",
    "    for con in cons[task_idx]:\n",
    "        print(\"current contrast: \" + con)\n",
    "        \n",
    "        cope_file_list = []\n",
    "        varcope_file_list = []\n",
    "        \n",
    "        for sub in np.asarray(participant_IDs): \n",
    "            sub = str(sub[0])\n",
    "            print(\"current subject: \"+ sub)\n",
    "            if iterative:\n",
    "                #iterative whole brain\n",
    "                \n",
    "                con_img_fname = '{}/{}_{}_fold_{}_exclude_none_con_*_{}_cope.nii.gz'.format(copes_dir, sub, task, '*', con)\n",
    "                print('CONFILE')\n",
    "                print(con_img_fname)\n",
    "                varcope_img_fname = '{}/{}_{}_fold_{}_exclude_none_con_*_{}_varcope.nii.gz'.format(varcopes_dir, sub, task, '*', con)\n",
    "                print('VARCOPEFILE')\n",
    "                print(varcope_img_fname)\n",
    "                \n",
    "                \n",
    "                con_matches = glob.glob(con_img_fname)\n",
    "                varcope_matches = glob.glob(varcope_img_fname)\n",
    "#                 print(con_matches)\n",
    "                \n",
    "                if len(con_matches) > 1 or len(varcope_matches) > 1:\n",
    "                    print('There are duplicate files present.')\n",
    "                elif len(con_matches) < 1 or len(varcope_matches) < 1:\n",
    "                    print(con_img_fname, 'is missing!')\n",
    "                else:\n",
    "                    cope_file_list.append(con_matches[0])\n",
    "                    varcope_file_list.append(varcope_matches[0])\n",
    "            else:\n",
    "                # non iterative whole brain\n",
    "                con_img_fname = '{}/{}_{}_{}_cope.nii.gz'.format(copes_dir, sub, task, con)\n",
    "                varcope_img_fname = '{}/{}_{}_{}_varcope.nii.gz'.format(varcopes_dir, sub, task, con)\n",
    "\n",
    "                if not op.isfile(con_img_fname):\n",
    "                    print(con_img_fname, 'is missing!')\n",
    "                else:\n",
    "                    cope_file_list.append(con_img_fname)\n",
    "                    varcope_file_list.append(varcope_img_fname)\n",
    "\n",
    "        \n",
    "        whole_group_outputdir = '{}/randomise_{}_{}'.format(whole_group_design_dir, task, con)\n",
    "        print('whole group output dir - per task, per contrast')\n",
    "        print(whole_group_outputdir)\n",
    "        os.makedirs(whole_group_outputdir, exist_ok = True)\n",
    "        \n",
    "        copefile = whole_group_outputdir + '/all_copes.nii.gz'\n",
    "        print(\"copes list\")\n",
    "        print(cope_file_list)\n",
    "        \n",
    "        \n",
    "        print('cope file output')\n",
    "        print(copefile)\n",
    "        \n",
    "        cmd = 'fslmerge -t ' + copefile + ' ' \n",
    "        cmd = cmd + ' '.join(cope_file_list)\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, shell = True)\n",
    "        print(\"Merged all copes\", result.stdout)\n",
    "        \n",
    "        \n",
    "\n",
    "        varcopefile = whole_group_outputdir + '/all_varcopes.nii.gz'\n",
    "        \n",
    "        print(\"varcopes list\")\n",
    "        print(varcope_file_list)\n",
    "        \n",
    "        \n",
    "        print('varcope file output')\n",
    "        print(varcopefile)\n",
    "        \n",
    "        cmd = 'fslmerge -t ' + varcopefile + ' ' \n",
    "        cmd = cmd + ' '.join(varcope_file_list)\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, shell = True)\n",
    "        print(\"Merged all varcopes\", result.stdout)\n",
    "\n",
    "        \n",
    "print('All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
