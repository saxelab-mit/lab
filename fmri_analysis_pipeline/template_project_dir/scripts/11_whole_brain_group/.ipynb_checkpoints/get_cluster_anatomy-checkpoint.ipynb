{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Anatomical Regions (by %) for significant group map clusters identified with FSL's cluster command\n",
    "\n",
    "\n",
    "The purpose of this notebook is to take significant clusters from group analysis outputs (whole brain analyses), and describe the anatomical parcellation that makes up the clusters, by percent. \n",
    "\n",
    "See relevant lab wiki here: https://github.mit.edu/Saxelab/fmri_analysis/wiki/thresholding-by-significance-and-cluster-size\n",
    "\n",
    "For example, say you have a significant clustes from a whole-brain group analysis. This script will say, for each cluster, X% of the cluster is in anatomical region A, Y% of the cluster is in anatomical region B. Etc. \n",
    "\n",
    "\n",
    "It is expected that you have a standard anatomical parcellation in the same template space as your data. Recommended is the Desikan-Killiany atlas, which you can access in our template space (MNI152NLin6Asym) here: \n",
    "\n",
    "https://github.com/neurodata/neuroparc \n",
    "\n",
    "> atlases/label/Human/Desikan_space-MNI152NLin6_res-2x2x2.nii.gz \n",
    "> atlases/label/Human/Anatomical-labels-csv/Desikan.csv \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "import glob\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = '/om2/group/saxelab/NES_fMRI/study2'\n",
    "\n",
    "tier_dir = op.join(proj_dir,'TIER')\n",
    "\n",
    "\n",
    "#group_analysis_dir = op.join(tier_dir,'analysis_data','group_analysis')\n",
    "group_analysis_dir = op.join(tier_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to files (outputs from FSL's cluster command, specifically the indices i.e. atlas of cluster identities)\n",
    "\n",
    "files = ['analysis_data/group_analysis/randomise_spWM_stimuli-gt-fixation/thresholded_tstat1_cluster_indices.nii.gz', \n",
    "         'analysis_data/group_analysis/randomise_DOTS_soc-gt-phys/thresholded_tstat1_cluster_indices.nii.gz', \n",
    "         'analysis_data/group_analysis/randomise_DOTS_phys-gt-soc/thresholded_tstat1_cluster_indices.nii.gz']\n",
    "\n",
    "# NOTE: atlas expected to be in folder according to atlas name (e.g., in a folder data/atlases/Desikan, \n",
    "# which would contain the template nii file and labels CSV below) \n",
    "\n",
    "atlas_folder = 'Desikan'\n",
    "atlas_template = 'Desikan_space-MNI152NLin6_res-2x2x2.nii.gz'\n",
    "atlas_labels = 'Desikan.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "atlas_path = op.join(proj_dir, 'data/atlases', atlas_folder)\n",
    "matches_atlas = glob.glob(op.join(atlas_path, atlas_template))\n",
    "matches_csv = glob.glob(op.join(atlas_path, atlas_labels))\n",
    "\n",
    "atlas_path = matches_atlas[0]\n",
    "atlas_labels_path = matches_csv[0]\n",
    "\n",
    "aicha_img = image.load_img(atlas_path)\n",
    "aicha = aicha_img.get_fdata()\n",
    "aicha_labels = pd.read_csv(atlas_labels_path, header=None)\n",
    "aicha_labels.columns = ['index', 'label']\n",
    "\n",
    "print('____________________ATLAS: ' + atlas_folder + '_____________________________')\n",
    "\n",
    "\n",
    "for clustermap_path in files: \n",
    "\n",
    "    # get name of test  \n",
    "    #verbose_name = clustermap_path.split('/')[0]\n",
    "    verbose_name = clustermap_path.split('/')[2] # changed for new paths, because ../ dir varies and is now in file names\n",
    "    test_name = verbose_name.split('randomise_')[1]\n",
    "\n",
    "    # get the path, load the image and data\n",
    "    fullimg_path = op.join(group_analysis_dir, clustermap_path)\n",
    "    clustermap_img = image.load_img(fullimg_path)\n",
    "    clustermap_data = clustermap_img.get_fdata()\n",
    "\n",
    "    # get the cluster index values (in descending order: '[::-1]')\n",
    "    clustermap_values = np.sort(pd.unique(np.ravel(clustermap_data)))[::-1]\n",
    "\n",
    "    print('\\n\\n\\n TEST: ', test_name, '\\n')\n",
    "\n",
    "    # for each cluster in the clustermap... \n",
    "    for cluster_index in clustermap_values:\n",
    "\n",
    "        # don't count 0 (empty / non-cluster voxels) \n",
    "        if cluster_index > 0:\n",
    "\n",
    "            # get a binary mask (start w/ boolean) for current cluster \n",
    "            boolean_clustermask = clustermap_data == cluster_index\n",
    "            binary_clustermask = boolean_clustermask.astype(int)\n",
    "\n",
    "            # make an image of this cluster\n",
    "            binary_clustermask_img = image.new_img_like(clustermap_img, binary_clustermask)\n",
    "\n",
    "            # mask the atlas with the binary cluster mask \n",
    "            clustermasked_atlas = image.math_img(\"img1 * img2\", img1 = aicha_img, img2 = binary_clustermask_img)\n",
    "            # load the data \n",
    "            clustermasked_atlas_data = clustermasked_atlas.get_fdata()\n",
    "\n",
    "            # get number of voxels in cluster (nonzero)\n",
    "            n_nonzero_voxels_in_cluster = sum(np.ravel(clustermasked_atlas_data > 0).astype(int))\n",
    "\n",
    "\n",
    "            # if cluster threshold is met \n",
    "            if n_nonzero_voxels_in_cluster >= 1: \n",
    "\n",
    "                # get the unique values in the clustermasked atlas (which regions are \"in\" this cluster)\n",
    "                masked_atlas_values = np.sort(pd.unique(np.ravel(clustermasked_atlas_data)))\n",
    "\n",
    "\n",
    "        #        print('\\n\\n')\n",
    "         #       print('CLUSTER INDEX: ', str(cluster_index))\n",
    "\n",
    "                # for each region/val in cluster_masked_aicha:\n",
    "                for region_index in masked_atlas_values: \n",
    "\n",
    "                    # exclude 0\n",
    "                    if region_index > 0:\n",
    "\n",
    "                        # get proportion of cluster in this region \n",
    "                        nvoxels_in_region = sum(np.ravel(clustermasked_atlas_data == region_index).astype(int))\n",
    "\n",
    "                        proportion_nvoxels_in_region = round(100*nvoxels_in_region/n_nonzero_voxels_in_cluster, 2)\n",
    "\n",
    "\n",
    "\n",
    "                        # get the label \n",
    "                        label = np.array(aicha_labels[aicha_labels['index'] == region_index])[0][1]\n",
    "\n",
    "                        if proportion_nvoxels_in_region > 0:\n",
    "\n",
    "                            df_currentrow = pd.DataFrame({\n",
    "                                'test': test_name,\n",
    "                                'cluster_idx': cluster_index,\n",
    "                                'value': proportion_nvoxels_in_region, \n",
    "                                'label': label,\n",
    "                                'str': str(proportion_nvoxels_in_region) + '% of cluster is in: ' + label\n",
    "                            }, index=[0])\n",
    "\n",
    "\n",
    "                            df_all = df_all.append(df_currentrow, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.sort_values(by = ['test', 'cluster_idx', 'value'], axis=0,ignore_index=True, ascending = [True, False, False], na_position = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_out = op.join(group_analysis_dir, 'RANDOMISE_CLUSTERS_PER_TEST.csv')\n",
    "df_all.to_csv(fname_out, index=False, header='column_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(fname_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_format_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for test in pd.unique(df_all['test']).tolist():\n",
    "    data_test = df_all[df_all['test'] == test]\n",
    "    for cluster_idx in pd.unique(data_test['cluster_idx']).tolist():\n",
    "        data_cluster = data_test[data_test['cluster_idx'] == cluster_idx]\n",
    "        cluster_str = ''\n",
    "        \n",
    "        for index, row in data_cluster.iterrows():\n",
    "            cur_percent = str(row['value'])\n",
    "            cur_region = row['label'].replace('_', ' ')\n",
    "            cur_str = cur_percent + '% ' + cur_region\n",
    "            if cluster_idx != 1:\n",
    "                cur_str += '; '\n",
    "                \n",
    "            cluster_str += cur_str\n",
    "            \n",
    "        df_currentrow = pd.DataFrame({\n",
    "                                    'test': test,\n",
    "                                    'str': cluster_str,\n",
    "                                    'cluster_idx': cluster_idx,\n",
    "                                }, index=[0])\n",
    "\n",
    "                                \n",
    "        table_format_df = table_format_df.append(df_currentrow, ignore_index=True)\n",
    "      \n",
    "    \n",
    "    \n",
    "fname_out = op.join(group_analysis_dir, 'RANDOMISE_CLUSTERS_PER_TEST_formattedStrings.csv')\n",
    "table_format_df.to_csv(fname_out, index=False, header='column_names')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
