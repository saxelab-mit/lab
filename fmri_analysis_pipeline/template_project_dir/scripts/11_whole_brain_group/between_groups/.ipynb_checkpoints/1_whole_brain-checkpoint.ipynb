{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "import glob\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tasks and cons from your BIDS/code/contrasts.tsv file\n",
    "# Second column is either 'description' or 'desc' in constrasts.tsv\n",
    "def get_cons_and_tasks(proj_dir, second_column='description'):\n",
    "    df = pd.read_csv(proj_dir + \"data/BIDS/code/contrasts_task-read.tsv\", sep=\"\\t\")\n",
    "    cons = []\n",
    "    tasks = []\n",
    "    for i, row in df.iterrows():\n",
    "        cons.append(\"con_%i_%s\" % (i+1, row[second_column].lower()))\n",
    "        if row['task'] not in tasks:\n",
    "            tasks.append(row['task'])\n",
    "    return cons, tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edit this line for your project\n",
    "proj_dir = '/nese/mit/group/saxelab/projects/EMOfd/'\n",
    "\n",
    "# COULD SET TO RUN ON SPECIFIC CONDS (or otherwise by list): \n",
    "# cons = [['con_1_tgn-gt-cgn', 'con_2_cgd-gt-cgn', 'con_3_cgf-gt-cgn',\n",
    "#         'con_4_cgf-gt-cgd', 'con_5_cgd-gt-cgf', 'con_6_cgn', 'con_7_cgd', \n",
    "#         'con_8_cgf', 'con_9_tgn']] # this is an array of (arrays of cons per task)\n",
    "# tasks = ['read']\n",
    "\n",
    "\n",
    "# OR GET CONS AND TASKS PROGRAMMATICALLY:  \n",
    "cons, tasks = get_cons_and_tasks(proj_dir)\n",
    "cons = [cons] \n",
    "\n",
    "\n",
    "\n",
    "groups = ['ENDORSE', 'OPPOSE']\n",
    "\n",
    "iterative = True #Did you do iterative subject-level modeling?\n",
    "\n",
    "master_data = op.join(proj_dir, 'data/subject_lists/EMOfd_subject_info_211026.csv')\n",
    "\n",
    "\n",
    "tier_proj_dir = proj_dir\n",
    "tier_dir = op.join(tier_proj_dir,'TIER')\n",
    "copes_dir = op.join(tier_dir,'original_data','copes')\n",
    "varcopes_dir = op.join(tier_dir,'original_data','varcopes')\n",
    "#masks_dir = op.join(tier_dir,'original_data','inverted_masks')\n",
    "flame_outputdir_root = op.join(tier_dir,'analysis_data','group_flame')\n",
    "do_allsubs_average = True\n",
    "\n",
    "between_group_design_dir = op.join(tier_dir, 'analysis_data/group_flame/between_group/')\n",
    "whole_group_design_dir = op.join(tier_dir, 'analysis_data/group_flame/whole_group/')\n",
    "\n",
    "print(cons, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(master_data)\n",
    "participant_IDs = pd.unique(df.loc[(df.exclude_from_analysis == False), 'participantID']).tolist()\n",
    "\n",
    "for ID in participant_IDs:\n",
    "    df.loc[df['participantID'] == ID, 'exclude_whole_row'] = False\n",
    "df = df[(df['exclude_whole_row'] == False) & (df['match'] == 1.0)]\n",
    "print(participant_IDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_idx, task in enumerate(tasks):\n",
    "    print(tasks[task_idx])\n",
    "\n",
    "    for con in cons[task_idx]:\n",
    "        print(con)\n",
    "        master_cope_file_list = []\n",
    "        master_varcope_file_list = []\n",
    "        \n",
    "        cope_file_list = []\n",
    "        varcope_file_list = []\n",
    "        group_cnts = []\n",
    "\n",
    "        for group in groups:\n",
    "            group_cnt = 0\n",
    "    \n",
    "            filesubs = pd.unique(df.loc[(df.exclude_whole_row == False) & (df.match == 1.0) &\n",
    "                                        (df.func_task == task) & (df.group == group),'participantID']).tolist()\n",
    "            for sub in filesubs:\n",
    "                if iterative:\n",
    "                    #iterative whole brain\n",
    "                    con_img_fname = '{}/{}_{}_fold_{}_exclude_none_{}_cope.nii.gz'.format(copes_dir, sub, task, '*', con)\n",
    "                    varcope_img_fname = '{}/{}_{}_fold_{}_exclude_none_{}_varcope.nii.gz'.format(varcopes_dir, sub, task, '*', con)\n",
    "\n",
    "                    con_matches = glob.glob(con_img_fname)\n",
    "                    varcope_matches = glob.glob(varcope_img_fname)\n",
    "                    if len(con_matches) > 1 or len(varcope_matches) > 1:\n",
    "                        print('There are duplicate files present.')\n",
    "                    elif len(con_matches) < 1 or len(varcope_matches) < 1:\n",
    "                        print(con_img_fname, 'is missing!')\n",
    "                    else:\n",
    "                        cope_file_list.append(con_matches[0])\n",
    "                        varcope_file_list.append(varcope_matches[0])\n",
    "                        group_cnt = group_cnt + 1\n",
    "                else:\n",
    "                    # non iterative whole brain\n",
    "                    con_img_fname = '{}/{}_{}_{}_cope.nii.gz'.format(copes_dir, sub, task, con)\n",
    "                    varcope_img_fname = '{}/{}_{}_{}_varcope.nii.gz'.format(varcopes_dir, sub, task, con)\n",
    "\n",
    "                    if not op.isfile(con_img_fname):\n",
    "                        print(con_img_fname, 'is missing!')\n",
    "                    else:\n",
    "                        cope_file_list.append(con_img_fname)\n",
    "                        varcope_file_list.append(varcope_img_fname)\n",
    "                        group_cnt = group_cnt + 1\n",
    "            \n",
    "            # actually do the merging, per group\n",
    "            flame_outputdir = '{}/{}_{}_betweengroups'.format(flame_outputdir_root, task,con)\n",
    "            os.makedirs(flame_outputdir, exist_ok = True)\n",
    "            copefile = flame_outputdir + '/all_copes_{}.nii.gz'.format(group)\n",
    "            cmd = 'fslmerge -t ' + copefile + ' ' \n",
    "\n",
    "            cmd = cmd + ' '.join(cope_file_list)\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, shell = True)\n",
    "            print(\"Merged copes for {}\".format(group), result.stdout)\n",
    "\n",
    "            varcopefile = flame_outputdir + '/all_varcopes_{}.nii.gz'.format(group)\n",
    "            cmd = 'fslmerge -t ' + varcopefile + ' ' \n",
    "            cmd = cmd + ' '.join(varcope_file_list)\n",
    "\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, shell = True)\n",
    "            print(\"Merged varcopes for {}\".format(group), result.stdout)\n",
    "            \n",
    "            group_cnts.append(group_cnt)\n",
    "            \n",
    "            master_cope_file_list += cope_file_list\n",
    "            master_varcope_file_list += varcope_file_list\n",
    "            cope_file_list = []\n",
    "            varcope_file_list = []\n",
    "        print(group_cnts)\n",
    "\n",
    "\n",
    "        if do_allsubs_average:\n",
    "            flame_whole_group_outputdir = '{}/{}_{}_allsubs'.format(flame_outputdir_root, task, con)\n",
    "            os.makedirs(flame_whole_group_outputdir, exist_ok = True)\n",
    "            \n",
    "            copefile = flame_outputdir + '/all_copes.nii.gz'\n",
    "            cmd = 'fslmerge -t ' + copefile + ' ' \n",
    "            cmd = cmd + ' '.join(master_cope_file_list)\n",
    "            print(len(master_cope_file_list))\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, shell = True)\n",
    "            print(\"Merged all copes\", result.stdout)\n",
    "            \n",
    "            varcopefile = flame_outputdir + '/all_varcopes.nii.gz'\n",
    "            cmd = 'fslmerge -t ' + varcopefile + ' ' \n",
    "            cmd = cmd + ' '.join(master_varcope_file_list)\n",
    "            result = subprocess.run(cmd, stdout=subprocess.PIPE, shell = True)\n",
    "            print(\"Merged all varcopes\", result.stdout)\n",
    "            \n",
    "            shutil.copy2(copefile, flame_whole_group_outputdir)\n",
    "            shutil.copy2(varcopefile, flame_whole_group_outputdir)\n",
    "            \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
